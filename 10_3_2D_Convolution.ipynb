{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcLoBBsK4iG6eTEIKW84pf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdumpling/Machine-Learning-Prince-/blob/main/10_3_2D_Convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Etw_QDxHyD4p"
      },
      "outputs": [],
      "source": [
        "# Yippie! We're hand coding a 2d convolution\n",
        "# I'm thinking that it's gonna be a lot of matrix multiplication or smt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "np.set_printoptions(precision=3,floatmode=\"fixed\")\n",
        "# learned that \"\" and '' are interchangable in Python\n",
        "torch.set_printoptions(precision=3)"
      ],
      "metadata": {
        "id": "2WhsNcciywOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do a convolution in PyTorch\n",
        "# padding: since we lose information around the perimeter, we can add padding around\n",
        "# stride: how far we shift the window\n",
        "def conv_pytorch(image, conv_weights, stride = 1, pad = 1):\n",
        "  image_tensor = torch.from_numpy(image) #creates tensor of the array\n",
        "  conv_weights_tensor = torch.from_numpy(conv_weights) #creates tensor of the weights\n",
        "  # let's do the convolution\n",
        "  # input and weights must be tensors\n",
        "  # other params include bias, dilation, and groups\n",
        "  output_tensor = torch.nn.functional.conv2d(image_tensor, conv_weights_tensor, stride = stride, padding = pad)\n",
        "  # convert tesnro back into NumPy array\n",
        "  return(output_tensor.numpy())"
      ],
      "metadata": {
        "id": "5Iw4H0quzXmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv 1 (no extra stride, channels, batch_size)"
      ],
      "metadata": {
        "id": "fEQ-Zdv_BWDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_numpy_1(image, weights, pad = 1):\n",
        "  # zero pad the image first (since we define a non-zero padding above)\n",
        "  if pad != 0:\n",
        "    # check padding definition later, basically padding with an array\n",
        "    image = np.pad(image, ((0,0), (0,0), (pad, pad), (pad,pad)), 'constant')\n",
        "\n",
        "  # get size of image and kernel\n",
        "  # what does image.shape return? check if there are 4 returns\n",
        "  #same with weights.shape\n",
        "  # or if we're setting all 4 to be the same thing\n",
        "  batchSize, channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
        "  channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
        "\n",
        "  # output arrays\n",
        "  # nvm, just basically counting how many kernelHeight's can fit in imageHeightIn\n",
        "  # +1 is like counting how many numbers between 3 and 6 inclusive (6-3+1)=4\n",
        "  imageHeightOut = np.floor(1+imageHeightIn-kernelHeight).astype(int)\n",
        "  imageWidthOut = np.floor(1+imageWidthIn-kernelWidth).astype(int)\n",
        "\n",
        "  # create output\n",
        "  out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype = np.float32)\n",
        "\n",
        "# outer two determine where the kernel is located\n",
        "  for c_y in range(imageHeightOut):\n",
        "    for c_x in range(imageWidthOut):\n",
        "      # inner two determine the product within the kernel\n",
        "      for c_kernel_y in range(kernelHeight):\n",
        "        for c_kernel_x in range(kernelWidth):\n",
        "          # first two for batchSize and channelsOut = 0 (we don't care now)\n",
        "          this_pixel_value = image[0, 0, c_y + c_kernel_y, c_x + c_kernel_x]\n",
        "          this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
        "\n",
        "          # do a lil sum and put it at the output indice\n",
        "          out[0,0,c_y, c_x] += this_pixel_value * this_weight\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "jkKiMVfQ30v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "n_batch = 1\n",
        "image_height = 4\n",
        "image_width = 6\n",
        "channels_in = 1\n",
        "channels_out = 1\n",
        "kernel_size = 3\n",
        "\n",
        "# random input image\n",
        "input_image = np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
        "# random conv kernel weights\n",
        "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
        "\n",
        "#conv in Pytorch\n",
        "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride = 1, pad = 1)\n",
        "print(\"PyTorch Results\")\n",
        "print(conv_results_pytorch)\n",
        "\n",
        "#conv in numpy\n",
        "print(\"Your results\")\n",
        "conv_results_numpy = conv_numpy_1(input_image, conv_weights)\n",
        "print(conv_results_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvAwEnYO_WNc",
        "outputId": "9be78c22-3b83-4e6b-d303-8a13c64c22a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Results\n",
            "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
            "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
            "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
            "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n",
            "Your results\n",
            "[[[[-0.929 -2.760  0.716  0.114  0.560 -0.387]\n",
            "   [-1.515  0.283  1.008  0.466 -1.094  2.004]\n",
            "   [-1.634  3.555 -2.154 -0.892 -1.856  2.299]\n",
            "   [ 0.565 -0.947 -0.629  2.996 -1.811 -0.533]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv 2 (Conv 1 + Stride)"
      ],
      "metadata": {
        "id": "go-JuREGBe7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_numpy_2(image, weights, stride, pad = 1):\n",
        "  if pad != 0:\n",
        "    image = np.pad(image, ((0,0), (0,0), (pad, pad), (pad,pad)), 'constant')\n",
        "\n",
        "  batchSize, channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
        "  channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
        "\n",
        "  imageHeightOut = np.floor(1+ (imageHeightIn-kernelHeight)/stride).astype(int)\n",
        "  imageWidthOut = np.floor(1+ (imageWidthIn-kernelWidth)/stride).astype(int)\n",
        "\n",
        "  out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype = np.float32)\n",
        "\n",
        "  for c_y in range(imageHeightOut):\n",
        "    for c_x in range(imageWidthOut):\n",
        "      for c_kernel_y in range(kernelHeight):\n",
        "        for c_kernel_x in range(kernelWidth):\n",
        "          # change c_y + c_kernel_y to stride*c_y+c_kernel_y\n",
        "          # accounts for shifting of the pixel_value by the stride\n",
        "          this_pixel_value = image[0, 0, stride * c_y + c_kernel_y, stride * c_x + c_kernel_x]\n",
        "          this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
        "\n",
        "          # do a lil sum and put it at the output indice\n",
        "          out[0,0,c_y, c_x] += this_pixel_value * this_weight\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "sIqKaPvzBh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed so we always get same answer\n",
        "np.random.seed(1)\n",
        "n_batch = 1\n",
        "image_height = 12\n",
        "image_width = 10\n",
        "channels_in = 1\n",
        "kernel_size = 3\n",
        "channels_out = 1\n",
        "stride = 2\n",
        "\n",
        "# Create random input image\n",
        "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
        "# Create random convolution kernel weights\n",
        "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
        "\n",
        "# Perform convolution using PyTorch\n",
        "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride, pad=1)\n",
        "print(\"PyTorch Results\")\n",
        "print(conv_results_pytorch)\n",
        "\n",
        "# Perform convolution in numpy\n",
        "print(\"Your results\")\n",
        "conv_results_numpy = conv_numpy_2(input_image, conv_weights, stride, pad=1)\n",
        "print(conv_results_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFS2nDd5Vkiu",
        "outputId": "c69d2413-1fc2-4bd9-ab47-69e6512dc6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Results\n",
            "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
            "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
            "   [-0.186  0.660  1.630  2.275  4.874]\n",
            "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
            "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
            "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n",
            "Your results\n",
            "[[[[-0.809 -4.550 -5.486 -9.506 -4.512]\n",
            "   [-0.055  1.145 -5.388 -3.910  0.097]\n",
            "   [-0.186  0.660  1.630  2.275  4.874]\n",
            "   [ 2.386 -0.225  3.288 -4.239 -1.403]\n",
            "   [ 0.825  1.710 -3.246  3.246  1.709]\n",
            "   [ 0.809  3.695  3.491 -2.113 -2.714]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv 3 (Conv 2 + Channels)"
      ],
      "metadata": {
        "id": "SxLIgjlXWDfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_numpy_3(image, weights, stride, pad = 1):\n",
        "  if pad != 0:\n",
        "    image = np.pad(image, ((0,0), (0,0), (pad, pad), (pad,pad)), 'constant')\n",
        "\n",
        "  batchSize, channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
        "  channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
        "\n",
        "  imageHeightOut = np.floor(1+ (imageHeightIn-kernelHeight)/stride).astype(int)\n",
        "  imageWidthOut = np.floor(1+ (imageWidthIn-kernelWidth)/stride).astype(int)\n",
        "\n",
        "  out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype = np.float32)\n",
        "\n",
        "  for c_y in range(imageHeightOut):\n",
        "    for c_x in range(imageWidthOut):\n",
        "      for c_channel_out in range(channelsOut):\n",
        "          for c_channel_in in range(channelsIn):\n",
        "            for c_kernel_y in range(kernelHeight):\n",
        "              for c_kernel_x in range(kernelWidth):\n",
        "                # change 2nd iterable dimension of image/weights to the in_channel\n",
        "                this_pixel_value = image[0, c_channel_in, stride * c_y + c_kernel_y, stride * c_x + c_kernel_x]\n",
        "                # weights now depend on both an in and out channel\n",
        "                this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
        "\n",
        "                # do a lil sum and put it at the output indice\n",
        "                # output will depend on the out channel\n",
        "                out[0,c_channel_out,c_y, c_x] += this_pixel_value * this_weight\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "yhatSIfxWG3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "n_batch = 1\n",
        "image_height = 4\n",
        "image_width = 6\n",
        "channels_in = 5\n",
        "kernel_size = 3\n",
        "channels_out = 2\n",
        "\n",
        "# Create random input image\n",
        "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
        "# Create random convolution kernel weights\n",
        "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
        "\n",
        "# Perform convolution using PyTorch\n",
        "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
        "print(\"PyTorch Results\")\n",
        "print(conv_results_pytorch)\n",
        "\n",
        "# Perform convolution in numpy\n",
        "print(\"Your results\")\n",
        "conv_results_numpy = conv_numpy_3(input_image, conv_weights, stride=1, pad=1)\n",
        "print(conv_results_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-dNFFwhWmvt",
        "outputId": "9f24623f-d198-4244-d727-c3d22a825de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Results\n",
            "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
            "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
            "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
            "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
            "\n",
            "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
            "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
            "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
            "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n",
            "Your results\n",
            "[[[[ -0.785   5.463  -2.480   5.026  -3.594   7.785]\n",
            "   [ -6.744   2.534  -0.664   7.149  -9.839   7.849]\n",
            "   [ -4.794  14.074  -1.060   2.706 -10.182   2.004]\n",
            "   [  1.809   0.287   4.648  -1.840   3.259   1.073]]\n",
            "\n",
            "  [[  4.150   5.372   1.699   0.500   0.589   4.361]\n",
            "   [ -4.123   5.136   4.677  -3.895  -4.990   2.546]\n",
            "   [  3.991   5.768  -2.315   8.473   1.752   2.766]\n",
            "   [  1.529   0.318  11.518  -5.444  -2.293   1.270]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conv 4 (Conv 3 + Multiple Images)"
      ],
      "metadata": {
        "id": "D6PONFwPW_Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_numpy_4(image, weights, stride, pad = 1):\n",
        "  if pad != 0:\n",
        "    image = np.pad(image, ((0,0), (0,0), (pad, pad), (pad,pad)), 'constant')\n",
        "\n",
        "  batchSize, channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
        "  channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
        "\n",
        "  imageHeightOut = np.floor(1+ (imageHeightIn-kernelHeight)/stride).astype(int)\n",
        "  imageWidthOut = np.floor(1+ (imageWidthIn-kernelWidth)/stride).astype(int)\n",
        "\n",
        "  out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype = np.float32)\n",
        "\n",
        "  for c_batch in range(batchSize):\n",
        "    for c_y in range(imageHeightOut):\n",
        "      for c_x in range(imageWidthOut):\n",
        "        for c_channel_out in range(channelsOut):\n",
        "            for c_channel_in in range(channelsIn):\n",
        "              for c_kernel_y in range(kernelHeight):\n",
        "                for c_kernel_x in range(kernelWidth):\n",
        "                  # change 2nd iterable dimension of image/weights to the in_channel\n",
        "                  # as well as 1st iterable dimension based on the batch size\n",
        "                  this_pixel_value = image[c_batch, c_channel_in, stride * c_y + c_kernel_y, stride * c_x + c_kernel_x]\n",
        "                  # weights now depend on both an in and out channel\n",
        "                  this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
        "\n",
        "                  # do a lil sum and put it at the output indice\n",
        "                  # output will depend on the out channel\n",
        "                  out[c_batch,c_channel_out,c_y, c_x] += this_pixel_value * this_weight\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "50d-Hi4hXIJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed so we always get same answer\n",
        "np.random.seed(1)\n",
        "n_batch = 2\n",
        "image_height = 4\n",
        "image_width = 6\n",
        "channels_in = 5\n",
        "kernel_size = 3\n",
        "channels_out = 2\n",
        "\n",
        "# Create random input image\n",
        "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))\n",
        "# Create random convolution kernel weights\n",
        "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))\n",
        "\n",
        "# Perform convolution using PyTorch\n",
        "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
        "print(\"PyTorch Results\")\n",
        "print(conv_results_pytorch)\n",
        "\n",
        "# Perform convolution in numpy\n",
        "print(\"Your results\")\n",
        "conv_results_numpy = conv_numpy_4(input_image, conv_weights, stride=1, pad=1)\n",
        "print(conv_results_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkp9F-CTXHOW",
        "outputId": "543c96c5-9359-4640-afa1-be71d7e7ec09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Results\n",
            "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
            "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
            "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
            "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
            "\n",
            "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
            "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
            "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
            "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
            "\n",
            "\n",
            " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
            "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
            "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
            "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
            "\n",
            "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
            "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
            "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
            "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n",
            "Your results\n",
            "[[[[ -3.633  -1.644   0.169  -1.167  -3.865   6.045]\n",
            "   [ -9.004   7.303   4.414   0.361  -6.739   3.939]\n",
            "   [ -1.391  13.502   3.807  -9.379   3.991   5.442]\n",
            "   [  2.805   6.874  -9.287  -4.468  -1.501   4.607]]\n",
            "\n",
            "  [[  1.940  -1.410   2.397  -0.235  -0.394  -1.483]\n",
            "   [  5.049  -3.335  -7.596  -1.586   3.049  -1.857]\n",
            "   [  3.514   0.475  -1.952  -1.291  -0.589  -0.948]\n",
            "   [  6.524  -0.020  -3.298  -1.248   3.249  -2.680]]]\n",
            "\n",
            "\n",
            " [[[  4.154  -4.764  11.635   0.506  -4.012  -2.081]\n",
            "   [ -1.125  -0.677  16.749  -7.030  -5.978  -2.629]\n",
            "   [  0.778  -3.984 -10.284   1.575  -8.888   1.163]\n",
            "   [  0.556  -2.290   1.407  -3.088   2.227  -5.403]]\n",
            "\n",
            "  [[  1.048   4.322  -0.901  -5.820   3.998   2.281]\n",
            "   [ -1.313   8.409  -0.100  14.625   1.223  -3.572]\n",
            "   [  1.411   1.617  -4.078  -8.107   3.705   0.229]\n",
            "   [ -3.540  -5.292  -5.619  -4.039  -4.048  -3.446]]]]\n"
          ]
        }
      ]
    }
  ]
}